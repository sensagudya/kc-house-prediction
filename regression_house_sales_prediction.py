# -*- coding: utf-8 -*-
"""regression-house-sales-prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oVs_eBp0nFuDduy32B_3oaATzldEmHPh

# **Prediksi Harga Rumah di King County, USA**
data: https://www.kaggle.com/datasets/harlfoxem/housesalesprediction

source of code example: https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Modeling%20House%20Price%20with%20Regularized%20Linear%20Model%20&%20Xgboost.ipynb
"""

from google.colab import drive
drive.mount('/content/drive')

#import package

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""## **Data Exploration**"""

#read data

house_data = pd.read_csv('/content/drive/My Drive/My Mini Projects/Kaggle - House/kc_house_data.csv')
house_data.head()

#atribut data

house_data.columns

#drop id dan date karena tampak tidak berpengaruh untuk menentukan prediksi harga rumah

house_data.drop(['id','date'], axis=1, inplace=True)

#ukuran dataframe

house_data.shape

#cek missing value

house_data.isnull().sum()

#statistic summary

house_data.describe()

#korelasi atribut lainnya dengan atribut 'price' (karena kita ingin bagaimana faktor lain mempengaruhi harga suatu rumah)

corr_with_price = house_data.corr()['price'].sort_values(ascending=False)
corr_with_price.drop('price').plot.bar()
plt.figure(figsize=(14,6))
plt.show()

#korelasi tertinggi sqft_living

#menampilkan bagaimana hubungan korelasi antara atribut dengan price itu terjadi
#yang dilihat adalah atribut-atribut dengan nilai korelasi tinggi, yaitu sqft_living, grade, sqft_above, sqft_living15

sns.pairplot(house_data[['price','sqft_living', 'grade', 'sqft_above', 'sqft_living15']])
plt.show()

"""## **Build Model**"""

#menentukan fitur pembelajaran dan label

X = house_data.drop(['price'],axis=1)
Y = house_data['price']

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X = scaler.fit_transform(X)

from sklearn.preprocessing import PolynomialFeatures
 
poly = PolynomialFeatures(degree = 2)
X = poly.fit_transform(X)

#splitting data train dan test

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=4)

"""### **Polynomial Ridge Regression**"""

from sklearn.linear_model import Ridge

ridge = Ridge(alpha = 50000)
ridge.fit(x_train,y_train)

#evaluation

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

y_pred = ridge.predict(x_test)
y_train_pred = ridge.predict(x_train)

r2_train = r2_score(y_train,y_train_pred)
r2_test = r2_score(y_test,y_pred)

rmse_train = np.sqrt(mean_squared_error(y_train,y_train_pred))
rmse_test = np.sqrt(mean_squared_error(y_test,y_pred))

print(r2_train, r2_test)
print(rmse_train, rmse_test)